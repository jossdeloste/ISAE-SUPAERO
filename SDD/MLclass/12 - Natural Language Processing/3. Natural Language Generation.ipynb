{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:22pt; line-height:25pt; font-weight:bold; text-align:center;\">Natural Language Generation</div>\n",
    "\n",
    "In this exercice, we will try out the approach of Natural Language Generation, using a Seq2Seq (sequence to sequence) architecture.\n",
    "\n",
    "Natural Language Generation has often used approaches close to \"fill-in-the-blanks\" templates. \n",
    "Seq2Seq Encoder-Decoder architectures make the issue of Natural Language Generation different, especially in the case of language translation.\n",
    "\n",
    "The approach is the following :\n",
    "1. A LSTM network encodes the input sequence into state vectors, with a predefined dimensionality\n",
    "2. A decoder LSTM predicts the next token of a target sequence based on the beginning o the sequence. The initial state is given by the encoder.\n",
    "\n",
    "The approach used here to train a system that predicts the next token based on the beginning of the sequence is called Teacher Forcing\n",
    "\n",
    "# 1. Parameters of the experiment\n",
    "\n",
    "In this example, we will train a system that translates basic french sentences into english. The data used for this example is a list of French sentences and their translation into english.\n",
    "\n",
    "# 1. Teacher forcing\n",
    "\n",
    "## 1.a Example\n",
    "\n",
    "Say we work with the following sequence :\n",
    "\n",
    "```\n",
    "Rien ne sert de courir il faut partir à point\n",
    "```\n",
    "\n",
    "We want to train a model that predicts the following word of the sequence based on the start of it. First, in order for the first word of the sequence and the end of it to be predicted, we need to add beginning and end tokens to the sequence. We decide to use \\t as the beginning token, and \\n as the end one :\n",
    "\n",
    "```\n",
    "\\t Rien ne sert de courir il faut partir à point \\n\n",
    "```\n",
    "\n",
    "When training the system, we start by inputing the \"\\t\" beginning token:\n",
    "\n",
    "```\n",
    "input: \n",
    "\\t\n",
    "prediction:\n",
    "sert\n",
    "```\n",
    "\n",
    "The untrained model generated \"sert\" where we expected \"Mary\". There are now two options to continue :\n",
    "\n",
    "### Without forcing :\n",
    "\n",
    "We add the previous output, \"sert\", to the input sequence, and continue generating :\n",
    "\n",
    "```\n",
    "input: \n",
    "\\t sert\n",
    "```\n",
    "\n",
    "With this approach, the error will propagate and make the model much slower to learn. \n",
    "\n",
    "### With teacher forcing\n",
    "\n",
    "After computing error, we discard the output \"sert\", and replace it with the word that was actually expected (\"Rien\"). This is called *teacher forcing* :\n",
    "\n",
    "```\n",
    "input: \n",
    "\\t Rien\n",
    "```\n",
    "\n",
    "Using his technique provides much faster training of the model.\n",
    "\n",
    "## 1.b. Implementing\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64  # Batch size for training.\n",
    "epochs = 50  # Number of epochs to train for.\n",
    "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
    "num_samples = 1000  # Number of samples to train on.\n",
    "\n",
    "# Path to the data\n",
    "data_path = 'datasets/enfratexts.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Vectorizing the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We vectorize the data using characters as features. \n",
    "\n",
    "\n",
    "For instance, if we only used the 26 letters of the alphabet to represent our data, the sequence \"Bonjour\" would be represented as a sequence of 7 (length of the sequence) 26th-dimensional sparse vectors. Each vector would have a \"1\" for the corresponding letter (here, the first input vector for the sequence \"Bonjour\" would have a 1 in the 2nd position, corresponding to the letter B)\n",
    "\n",
    "\n",
    "Of course, our input data may contain more characters than just 26 letters. We may have accents, numbers, symbols... And also don't forget that we are using two special characters \"\\t\" for start of sequence and \"\\n\" for end of sequence.\n",
    "\n",
    "\n",
    "Knowing this, the first step is to :\n",
    "- Figure out how many different characters we need to vectorize our input sequences (in french) and target sequences (in english). We can of course expect different dimensionnalities for different languages.\n",
    "- Figure out the maximum size of the input sequences, for encoding.\n",
    "- Vectorize each of the input and target sequences, for our training data.\n",
    "\n",
    "## 2.1. First step : defining the vector space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of input tokens: 75\n",
      "Number of output tokens: 65\n",
      "Max sequence length of inputs: 31\n",
      "Max sequence length of outputs: 12\n"
     ]
    }
   ],
   "source": [
    "input_texts = [] #input texts (french)\n",
    "target_texts = [] #target texts (english)\n",
    "input_characters = set() #the set that will contain all the input characters, used for vectorizing\n",
    "target_characters = set() #same as above, for target\n",
    "\n",
    "#Read each line of the file containing data\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "\n",
    "# Run through the lines and isolate input (french) and target (english) texts\n",
    "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "    target_text, input_text, _ = line.split('\\t')\n",
    "    # We use \"\\t\" as the start sequence character, and \"\\n\" as end sequence character.\n",
    "    target_text = '\\t' + target_text + '\\n'\n",
    "    # List of input texts\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    # We list the characters required for encoding, by storing all unique characters in the sequences\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)\n",
    "\n",
    "            \n",
    "input_characters = sorted(list(input_characters)) #List of all required characters to encode input sequences\n",
    "target_characters = sorted(list(target_characters)) #List of all required characters to encode target sequences\n",
    "\n",
    "# Dimensions of the encoding and decoding spaces\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
    "\n",
    "\n",
    "print('Number of input tokens:', num_encoder_tokens)\n",
    "print('Number of output tokens:', num_decoder_tokens)\n",
    "print('Max sequence length of inputs:', max_encoder_seq_length)\n",
    "print('Max sequence length of outputs:', max_decoder_seq_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Second step : vectorizing \n",
    "\n",
    "Prepare the vectors with the right dimensions that will hold the input data of the encoder, the output data of the decoder, and the input data of the decoder.\n",
    "\n",
    "**Reminder : \n",
    "- The encoder will use the input sequences as an input. The dimensionnality of their vectorized form will be the size of the character space, times the length of the biggest sequence\n",
    "- The decoder is meant to predict the next step of the sequence, based on the beginning of it. Consequently, its inputs and outputs will have the same dimensionnality.\n",
    "**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Dictionnaries for vectorizing sequences, or restore vectorized sequences to readable format\n",
    "input_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(target_characters)])\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token_index.items())\n",
    "\n",
    "\n",
    "#empty vectors to hold encoder and decoder data\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, We prepare the vectorized sequences. \n",
    "\n",
    "**Reminder : The decoder target data is the same as the input data, but ahead by one step.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
    "        #Fill the rest of the input sequence with spaces, until the max length is reached\n",
    "    encoder_input_data[i, t + 1:, input_token_index[' ']] = 1.\n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one step and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n",
    "        #Fill the rest of the sequence with spaces, until the max length is reached    \n",
    "    decoder_input_data[i, t + 1:, target_token_index[' ']] = 1.\n",
    "    decoder_target_data[i, t:, target_token_index[' ']] = 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0. Defining the Encoder-Decoder Architecture\n",
    "\n",
    "## 3.1. Encoder\n",
    "\n",
    "Encoding is performed via a LSTM, whose state we will store to condition the decoding. The output is discarded, and we only keep the states (see teacher forcing explanation, earlier in this notebook).\n",
    "Earlier in this notebook, we defined the latent dimensionnality of the encoder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\durantga\\appdata\\local\\continuum\\anaconda3\\envs\\courssup\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "\n",
    "# Define an input sequence and process it.\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Decoder\n",
    "\n",
    "Decoding is performed through lstm and a softmax layer (used to predict character probabilities).\n",
    "During inference, we will need to use the internal states of the decoder (see lower). We need to define the decoder accordingly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "# We define our decoder to return full output sequences, and to return internal states as well. We won't use the\n",
    "# return states during trainging, but use them during inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Full model\n",
    "\n",
    "We define the model :\n",
    "- using two inputs: the encoder inputs (french sentences) and decoder inputs (english sentences)\n",
    "- returning the decoder outputs (english sentences ahead of one step)\n",
    "\n",
    "Run a few epochs (50 only, and on 1000 documents, to save memory and time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Training the Seq2Seq model\n",
    "\n",
    "In this example, we propose to train on 80% of the data and test on 20% of the data. \n",
    "For processing time reasons, we propose to limit the size of training data as well as the number of epochs we run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/5\n",
      "800/800 [==============================] - 4s 6ms/step - loss: 0.9078 - accuracy: 0.7181 - val_loss: 1.8784 - val_accuracy: 0.4842\n",
      "Epoch 2/5\n",
      "800/800 [==============================] - 4s 4ms/step - loss: 0.8146 - accuracy: 0.7476 - val_loss: 1.9651 - val_accuracy: 0.4679\n",
      "Epoch 3/5\n",
      "800/800 [==============================] - 3s 4ms/step - loss: 0.8034 - accuracy: 0.7523 - val_loss: 2.0789 - val_accuracy: 0.4654\n",
      "Epoch 4/5\n",
      "800/800 [==============================] - 3s 4ms/step - loss: 0.7997 - accuracy: 0.7508 - val_loss: 1.9438 - val_accuracy: 0.4717\n",
      "Epoch 5/5\n",
      "800/800 [==============================] - 3s 4ms/step - loss: 0.7819 - accuracy: 0.7580 - val_loss: 1.8939 - val_accuracy: 0.4854\n"
     ]
    }
   ],
   "source": [
    "# Run training\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=5,\n",
    "          validation_split=0.2)\n",
    "# Save model\n",
    "model.save('nlg_encode_decode_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Inference\n",
    "\n",
    "First, we need to define the models required to perform inference\n",
    "\n",
    "1) encode input and retrieve initial decoder state\n",
    "2) run one step of decoder with this initial state and a \"start of sequence\" token as target. Output will be the next target token\n",
    "3) Repeat with the current target token and current states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1.Define encoder model transforming the encoder input into the states of the encoding LSTM\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# 2.Define decoder : the initial states of the decoder are also an input of the model (input from the encoder)\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "# Decoder LSTM\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "# Decode softmax layer\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "# Full decoder model : \n",
    "# - it takes the decoder inputs (english sequences) as well as the initial states as inputs\n",
    "# - it returns the decoder outputs (english sequence ahead by one step) and the current states (that will be used for the next inference step)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then write a function that will perform decoding. The steps for decoding are the following :\n",
    "- We encode the input sequence, and retrieve the states (step 1 in the cell above)\n",
    "- We run one step of the decoder, using the initial state retrieved from the encoder, and a sequence containing only a start of sequence token \"\\t\". \n",
    "- From this step, we retrieve the output sequence and states of the decoder\n",
    "- We then repeat the 2 previous steps with the updated output sequence and states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    # Sampling loop for sequences\n",
    "    stop_condition = False #Defines when to stop iterating\n",
    "    decoded_sentence = '' #Will hold the decoded sequence\n",
    "    while not stop_condition:\n",
    "        \n",
    "        ## PREDICTING\n",
    "        #Run one step of decoder using the target_seq and states as input\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Get the decode token : we check which token is the most likely, decode it using the mapping dictionary, \n",
    "        # and then add it to the decoded sequeces\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length or predict stop character.\n",
    "        if (sampled_char == '\\n' or len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        # UPDATING\n",
    "        # Update the target sequence using the predicted token as input.\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "        # Update states to the current states of the lstm\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. Run inference\n",
    "\n",
    "In this simple example, we under-trained our model for memory and processing time reasons. We propose to see what the output looks like using some of the first sequences we used during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "French Sentence: Va !\n",
      "English Translation: Go away.\n",
      "\n",
      "French Sentence: Salut !\n",
      "English Translation: Go away.\n",
      "\n",
      "French Sentence: Salut.\n",
      "English Translation: Go away.\n",
      "\n",
      "French Sentence: Cours !\n",
      "English Translation: We lost.\n",
      "\n",
      "French Sentence: Courez !\n",
      "English Translation: Go away.\n",
      "\n",
      "French Sentence: Qui ?\n",
      "English Translation: We lost.\n",
      "\n",
      "French Sentence: Ça alors !\n",
      "English Translation: Who fun?\n",
      "\n",
      "French Sentence: Au feu !\n",
      "English Translation: Go away.\n",
      "\n",
      "French Sentence: À l'aide !\n",
      "English Translation: Go away.\n",
      "\n",
      "French Sentence: Saute.\n",
      "English Translation: Go away.\n",
      "\n",
      "French Sentence: Ça suffit !\n",
      "English Translation: We lost.\n",
      "\n",
      "French Sentence: Stop !\n",
      "English Translation: Go away.\n",
      "\n",
      "French Sentence: Arrête-toi !\n",
      "English Translation: Go away.\n",
      "\n",
      "French Sentence: Attends !\n",
      "English Translation: Go away.\n",
      "\n",
      "French Sentence: Attendez !\n",
      "English Translation: Go away.\n",
      "\n",
      "French Sentence: Poursuis.\n",
      "English Translation: Go away.\n",
      "\n",
      "French Sentence: Continuez.\n",
      "English Translation: Help up.\n",
      "\n",
      "French Sentence: Poursuivez.\n",
      "English Translation: Go away.\n",
      "\n",
      "French Sentence: Bonjour !\n",
      "English Translation: Go away.\n",
      "\n",
      "French Sentence: Salut !\n",
      "English Translation: Go away.\n",
      "\n",
      "French Sentence: Je comprends.\n",
      "English Translation: I saw you.\n",
      "\n",
      "French Sentence: J'essaye.\n",
      "English Translation: I saw you.\n",
      "\n",
      "French Sentence: J'ai gagné !\n",
      "English Translation: I saw you.\n",
      "\n",
      "French Sentence: Je l'ai emporté !\n",
      "English Translation: I saw you.\n",
      "\n",
      "French Sentence: J’ai gagné.\n",
      "English Translation: I saw you.\n",
      "\n",
      "French Sentence: Oh non !\n",
      "English Translation: Go away.\n",
      "\n",
      "French Sentence: Attaque !\n",
      "English Translation: Go away.\n",
      "\n",
      "French Sentence: Attaquez !\n",
      "English Translation: Go away.\n",
      "\n",
      "French Sentence: Santé !\n",
      "English Translation: Go away.\n",
      "\n",
      "French Sentence: À votre santé !\n",
      "English Translation: We lost.\n",
      "\n",
      "French Sentence: Merci !\n",
      "English Translation: Who fun?\n",
      "\n",
      "French Sentence: Tchin-tchin !\n",
      "English Translation: Whe st.\n",
      "\n",
      "French Sentence: Lève-toi.\n",
      "English Translation: Go away.\n",
      "\n",
      "French Sentence: Va, maintenant.\n",
      "English Translation: Go away.\n",
      "\n",
      "French Sentence: Allez-y maintenant.\n",
      "English Translation: Go away.\n",
      "\n",
      "French Sentence: Vas-y maintenant.\n",
      "English Translation: Go away.\n",
      "\n",
      "French Sentence: J'ai pigé !\n",
      "English Translation: I saw you.\n",
      "\n",
      "French Sentence: Compris !\n",
      "English Translation: Go away.\n",
      "\n",
      "French Sentence: Pigé ?\n",
      "English Translation: Go away.\n",
      "\n",
      "French Sentence: Compris ?\n",
      "English Translation: Go away.\n",
      "\n",
      "French Sentence: T'as capté ?\n",
      "English Translation: Go away.\n",
      "\n",
      "French Sentence: Monte.\n",
      "English Translation: It's here.\n",
      "\n",
      "French Sentence: Montez.\n",
      "English Translation: How nice.\n",
      "\n",
      "French Sentence: Serre-moi dans tes bras !\n",
      "English Translation: Go away.\n",
      "\n",
      "French Sentence: Serrez-moi dans vos bras !\n",
      "English Translation: Go away.\n",
      "\n",
      "French Sentence: Je suis tombée.\n",
      "English Translation: I saw you.\n",
      "\n",
      "French Sentence: Je suis tombé.\n",
      "English Translation: I saw you.\n",
      "\n",
      "French Sentence: Je sais.\n",
      "English Translation: I saw you.\n",
      "\n",
      "French Sentence: Je suis parti.\n",
      "English Translation: I saw you.\n",
      "\n",
      "French Sentence: Je suis partie.\n",
      "English Translation: I saw you.\n",
      "\n",
      "French Sentence: J'ai perdu.\n",
      "English Translation: I saw you.\n",
      "\n",
      "French Sentence: J’ai payé.\n",
      "English Translation: I saw you.\n",
      "\n",
      "French Sentence: J'ai 19 ans.\n",
      "English Translation: I saw you.\n",
      "\n",
      "French Sentence: Je vais bien.\n",
      "English Translation: I saw you.\n",
      "\n",
      "French Sentence: Ça va.\n",
      "English Translation: I saw you.\n",
      "\n",
      "French Sentence: Écoutez !\n",
      "English Translation: Go away.\n",
      "\n",
      "French Sentence: C'est pas possible !\n",
      "English Translation: It's fane.\n",
      "\n",
      "French Sentence: Impossible !\n",
      "English Translation: How nice.\n",
      "\n",
      "French Sentence: En aucun cas.\n",
      "English Translation: How nice.\n",
      "\n",
      "French Sentence: Sans façons !\n",
      "English Translation: Go away.\n",
      "\n",
      "French Sentence: C'est hors de question !\n",
      "English Translation: I saw you.\n",
      "\n",
      "French Sentence: Il n'en est pas question !\n",
      "English Translation: I saw you.\n",
      "\n",
      "French Sentence: C'est exclu !\n",
      "English Translation: I saw you.\n",
      "\n",
      "French Sentence: En aucune manière !\n",
      "English Translation: How nice.\n",
      "\n",
      "French Sentence: Hors de question !\n",
      "English Translation: It's fane.\n",
      "\n",
      "French Sentence: Vraiment ?\n",
      "English Translation: Go away.\n",
      "\n",
      "French Sentence: Vrai ?\n",
      "English Translation: Go away.\n",
      "\n",
      "French Sentence: Ah bon ?\n",
      "English Translation: We lost.\n",
      "\n",
      "French Sentence: Merci !\n",
      "English Translation: Who fun?\n",
      "\n",
      "French Sentence: On essaye.\n",
      "English Translation: Help up.\n",
      "\n",
      "French Sentence: Nous avons gagné.\n",
      "English Translation: We lost.\n",
      "\n",
      "French Sentence: Nous gagnâmes.\n",
      "English Translation: Go away.\n",
      "\n",
      "French Sentence: Nous l'avons emporté.\n",
      "English Translation: We lost.\n",
      "\n",
      "French Sentence: Nous l'emportâmes.\n",
      "English Translation: Go away.\n",
      "\n",
      "French Sentence: Demande à Tom.\n",
      "English Translation: Go away.\n",
      "\n",
      "French Sentence: Fantastique !\n",
      "English Translation: Go away.\n",
      "\n",
      "French Sentence: Sois calme !\n",
      "English Translation: Go away.\n",
      "\n",
      "French Sentence: Soyez calme !\n",
      "English Translation: Go away.\n",
      "\n",
      "French Sentence: Soyez calmes !\n",
      "English Translation: Go away.\n",
      "\n",
      "French Sentence: Sois détendu !\n",
      "English Translation: Go away.\n",
      "\n",
      "French Sentence: Sois juste !\n",
      "English Translation: Go away.\n",
      "\n",
      "French Sentence: Soyez juste !\n",
      "English Translation: Go away.\n",
      "\n",
      "French Sentence: Soyez justes !\n",
      "English Translation: Go away.\n",
      "\n",
      "French Sentence: Sois équitable !\n",
      "English Translation: Go away.\n",
      "\n",
      "French Sentence: Soyez équitable !\n",
      "English Translation: Go away.\n",
      "\n",
      "French Sentence: Soyez équitables !\n",
      "English Translation: Go away.\n",
      "\n",
      "French Sentence: Sois gentil.\n",
      "English Translation: Go away.\n",
      "\n",
      "French Sentence: Sois gentil !\n",
      "English Translation: Go away.\n",
      "\n",
      "French Sentence: Sois gentille !\n",
      "English Translation: Go away.\n",
      "\n",
      "French Sentence: Soyez gentil !\n",
      "English Translation: Go away.\n",
      "\n",
      "French Sentence: Soyez gentille !\n",
      "English Translation: Go away.\n",
      "\n",
      "French Sentence: Soyez gentils !\n",
      "English Translation: Go away.\n",
      "\n",
      "French Sentence: Soyez gentilles !\n",
      "English Translation: Go away.\n",
      "\n",
      "French Sentence: Dégage !\n",
      "English Translation: Go away.\n",
      "\n",
      "French Sentence: Appelle-moi !\n",
      "English Translation: Go away.\n",
      "\n",
      "French Sentence: Appellez-moi !\n",
      "English Translation: Go away.\n",
      "\n",
      "French Sentence: Appelle-nous !\n",
      "English Translation: Go away.\n",
      "\n",
      "French Sentence: Appelez-nous !\n",
      "English Translation: Go away.\n",
      "\n",
      "French Sentence: Entrez !\n",
      "English Translation: Help up.\n",
      "\n",
      "French Sentence: Entre.\n",
      "English Translation: It's fane.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for seq_index in range(100):\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('French Sentence:', input_texts[seq_index])\n",
    "    print('English Translation:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
