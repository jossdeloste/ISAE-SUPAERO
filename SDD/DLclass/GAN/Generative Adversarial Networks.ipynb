{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Generative Adversarial Networks (GAN)\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"><img alt=\"Creative Commons License\" align=\"left\" src=\"https://i.creativecommons.org/l/by-nc-sa/4.0/80x15.png\" /></a>&nbsp;| Dennis G. Wilson | <a href=\"https://supaerodatascience.github.io/deep-learning/\">https://supaerodatascience.github.io/deep-learning/</a>\n",
    "\n",
    "adapted from the GAN class of Thomas Pierrot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Warning :</b>\n",
    "This notebook is heavy on computational resources. Depending on your personal machine, it might be better to run it on <a href=\"https://colab.research.google.com/github/SupaeroDataScience/deep-learning/blob/main/GAN/Generative%20Adversarial%20Networks.ipynb\">Colab</a>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import itertools\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The goal of GANs\n",
    "\n",
    "<b>Generative Adversarial Networks (GAN)</b> are a framework for generating new data which follows an existing distribution. This is often used with images is to generate images which look real, but which don't exist in the training set. The example we'll use today is the MNIST dataset, so we will generate new images which look like handwritten digits but which are created by a neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"img/distributions.png\">\n",
    "\n",
    "Goodfellow, Ian, et al. \"Generative adversarial nets.\" Advances in neural information processing systems. 2014. [pdf](https://arxiv.org/pdf/1406.2661.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In this framework, two assumptions have to be made:\n",
    "+ All the data from the training dataset is assumed to follow the same probability distribution noted $p_{data}$. In other words, if the MNIST database is considered, all the 28x28 matrices which represent hand-written numbers are assumed to follow the same probability distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "+ The database is assumed large enough that the probability distribution obtained represent well and only those data. In other words, if new sample can be generated from this distribution, they should look like the other elements of the database. In the case of the MNIST database, if new 28x28 matrices may be generated from the distribution $p_{data}$, then they should still represent hand-written numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: MNIST\n",
    "\n",
    "We'll use the MNIST dataset for the exercise today. We'll download this dataset and make batching data loaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# set batch_size\n",
    "batch_size = 128\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "# we normalize data to have values between -1 and 1\n",
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5], std=[0.5]) ])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='../data/', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "train_iterator = iter(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "As a reminder, let's look at some example digits from the MNIST set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "num_test_samples = 16 # number of digits to plot\n",
    "\n",
    "# create figure for plotting\n",
    "size_figure_grid = int(math.sqrt(num_test_samples))\n",
    "fig, ax = plt.subplots(size_figure_grid, size_figure_grid, figsize=(6, 6))\n",
    "for i, j in itertools.product(range(size_figure_grid), range(size_figure_grid)):\n",
    "    ax[i,j].get_xaxis().set_visible(False)\n",
    "    ax[i,j].get_yaxis().set_visible(False)\n",
    "\n",
    "# load a batch of training data\n",
    "images, labels = next(train_iterator)\n",
    "\n",
    "# show a subpart of it\n",
    "for k in range(num_test_samples):\n",
    "    i = k//4\n",
    "    j = k%4\n",
    "    ax[i,j].cla()\n",
    "    ax[i,j].imshow(images[k,:].data.cpu().numpy().reshape(28, 28), cmap='Greys')\n",
    "    display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The task for today is to learn to generate new images which look like these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Generator\n",
    "\n",
    "<img src=\"img/generator_schema.png\">\n",
    "\n",
    "One network - called the <b>Generator</b>- is built and is meant to transform vectors following a random probability distribution $p_z$ - called noise probability distribution - in vectors following natural data distribution $p_{data}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "To follow the MNIST example, the generator will take as input vectors of real numbers following a gaussian distribution, $p_z$ and should output a 28x28 matrix whose values follow the data probability distribution followed by MNIST images, $p_{data}$. Hence, that network role would be to transform a gaussian distribution into a probability distribution represented by the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Discriminator\n",
    "\n",
    "<img src=\"img/discriminator_schema.png\">\n",
    "\n",
    "To train the generator, we use a second network called the **Discriminator**. The role of this network is to learn the data distribution $p_{data}$ in order to classify if a sample comes from this distribution or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The <b>Discriminator</b>'s goal is to differentiate between samples following the real data probability distribution and samples generated by the generator. It takes as an input either a real sample or a sample output from the generator and is trained to return the likelihood of the image being real. In the maximum, the discriminator is expected to return 1 when it is given an image from the training dataset and to return 0 when it is given an image generated by the generator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The **adversarial** aspect of the networks comes from the training methods. The generator is trained to fool the discriminator : ie to make it return 1 for generated samples. The networks play a 2-player minimax game. At the equilibrium, the discriminator should always return 0.5 : it cannot make the difference between real and fake samples anymore, hence the fake samples follow the same probability distribution than real ones. The generator is trained towards this result and ends up producing realistic results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To get a better understanding, let us call G the generator, D the discriminator, $z$ a variable following the noise probability distribution $p_z$ and $x$ a variable following the data probability distribution $p_{data}$. Let us call as well $p_g$ the probability distribution followed by Gâ€™s outputs : $G(z)$. Then the generator's goal is to fool the discriminator returning real-like samples which means equalizing $p_g \\approx p_{data}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The discriminator is trained to return $1$ for real data : $D(x) = 1$ and $0$ for fake data $D(G(z)) = 0$ while the generator is trained to make the discriminator returning $1$ as well for fake data. Hence, D and G play the two-player minimax game with value function $V(G, D)$:\n",
    "\n",
    "$$\\min_{G} \\max_{D} V(D,G)  = \\mathbb{E}_{x\\sim p_{data}}[log D(x)] + \\mathbb{E}_{z\\sim p_{z}}[log(1 - D(G(z)))]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The implementation of this game results in the following algorithm, described in the original GAN paper:\n",
    "\n",
    "<img src=\"img/gan_algo.png\" style=\"max-width:100%; width: 70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# GANs in Practice\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Build the neural networks\n",
    "\n",
    "We now build both the networks. In this notebook, as in the original paper, both will be simple fully connected network.\n",
    "\n",
    "<img src=\"img/schema_gan_mnist.png\" style=\"max-width:100%; width: 70%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We'll start with a simple **Discriminator** model of feed-forward LeakyReLU units. We'll also add Dropout at each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(784, 1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.model(x.view(x.size(0), 784))\n",
    "        out = out.view(out.size(0), -1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <h2>Exercise 1</h2>\n",
    "\n",
    "Write the generator code. It should take a vector of size 100 as input and output a flattened vector of 784 pixels. You can use feed-forward layers, similar to the Discriminator. What activation function should the final layer have? Consider that it is supposed to output black and white pixel values.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# %load solutions/1_generator.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Once the class are written, we instantiate the networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "discriminator = Discriminator()\n",
    "generator = Generator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's load some example data to go through the training steps. First we'll load the images and generate the labels. Note that the label for training the discriminator is not the number drawn in the image; it is simply 1 for all images from the real data set and 0 for all images from the generated set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "images, _ = next(train_iterator)\n",
    "images = Variable(images)\n",
    "real_labels = Variable(torch.ones(images.size(0), 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "To use the generator, we create $p_z$ following a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Sample from generator\n",
    "noise = Variable(torch.randn(images.size(0), 100))\n",
    "fake_images = generator(noise)\n",
    "fake_labels = Variable(torch.zeros(images.size(0), 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what sort of images our random generator creates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,4))\n",
    "for i in range(4):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.imshow(fake_images[i,:].data.cpu().numpy().reshape(28, 28), cmap='Greys')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "As could be expected, the random generator gives random noise images. We shouldn't expect much of a difference from the discriminator, given that its random. However, since the MNIST distribution $x$ and generated distribution $D(x)$ are so clearly different, even a random discriminitor should have a different output given these two inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "d_real = discriminator(images)\n",
    "d_fake = discriminator(fake_images)\n",
    "d_real.detach().numpy()[:5], d_fake.detach().numpy()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We'll now train the discriminator and generator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss function we'll use in training is the [Binary Cross-Entropy loss](https://pytorch.org/docs/stable/_modules/torch/nn/modules/loss.html#BCELoss). Looking at the PyTorch documentation, we can see that, by default, the `reduction` operator for $L$ is set to ``'mean'``, making the loss function:\n",
    "\n",
    "$\\ell(x, y) = L = \\frac{1}{N}\\sum\\{l_1,\\dots,l_N\\}$\n",
    "\n",
    "$l_n = - w_n \\left[ y_n \\cdot \\log x_n + (1 - y_n) \\cdot \\log (1 - x_n) \\right]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "criterion(d_real, real_labels), criterion(d_fake, fake_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This corresponds to the loss function defined above for the GAN:\n",
    "\n",
    "$$\\min_{G} \\max_{D} V(D,G)  = \\mathbb{E}_{x\\sim p_{data}}[log D(x)] + \\mathbb{E}_{z\\sim p_{z}}[log(1 - D(G(z)))]$$\n",
    "\n",
    "where for real data, $y_n$ is 1 and for generated data, $y_n$ is 0. We want the discriminator to predict 1 if the data is real and 0 if it is generated. This corresponds to the variables `real_labels` and `fake_labels`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also define the optimizers, simply using Adam for both the discriminiator and generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0002\n",
    "d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "g_optimizer = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <h2>Exercise 2.</h2>\n",
    "\n",
    "Write a training step for the discriminiator. The function definition is below. Fill in this missing components.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_discriminator(discriminator, images, real_labels, fake_images, fake_labels):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        discriminator: discriminator model object\n",
    "        images: a batch of data from the dataset\n",
    "        real_labels: a vector of ones, size of images\n",
    "        fake_images: a batch of images generated by the generator\n",
    "        fake_labels: a vector of zeros, size of fake_images\n",
    "    \n",
    "    Returns:\n",
    "        d_loss: discriminator loss\n",
    "        real_output: output of the discriminator on the real images\n",
    "        fake_output: output of the discrimiator on the fake images\n",
    "    \"\"\"    \n",
    "    discriminator.zero_grad()\n",
    "    # TODO: complete the code\n",
    "    # d_loss =\n",
    "    d_loss.backward()\n",
    "    d_optimizer.step()\n",
    "    return d_loss, real_output, fake_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/2_train_d.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The second part of the min-max equation is the generator.\n",
    "\n",
    "$$\\min_{G} \\max_{D} V(D,G)  = \\mathbb{E}_{x\\sim p_{data}}[log D(x)] + \\mathbb{E}_{z\\sim p_{z}}[log(1 - D(G(z)))]$$\n",
    "\n",
    "Considering a static discriminator D, we have \n",
    "\n",
    "$$\\min_{G} V(D,G)  = \\mathbb{E}_{x\\sim p_{data}}[log D(x)] + \\mathbb{E}_{z\\sim p_{z}}[log(1 - D(G(z)))]$$\n",
    "\n",
    "However, the generator doesn't influence $\\mathbb{E}_{x\\sim p_{data}}[log D(x)]$. The generator's loss is therefore only\n",
    "\n",
    "$$\\min_{G} V(D,G)  = \\mathbb{E}_{z\\sim p_{z}}[log(1 - D(G(z)))]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Note that other loss metrics have been proposed for GANs to encourage more stable training. For example, at the beginning of training, the discriminator's job is easy and so it might train much faster than the generator, halting the adversarial training. In order to increase early gradients, it is proposed to maximize $log(D(G(z)))$ instead of minimizing $log(1-D(G(z)))$ for the generator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Another loss function is using in the [Wasserstein GAN](https://arxiv.org/abs/1701.07875), which transforms the discriminator into a critic, outputting a real value which should be larger for real inputs than fake ones. The discriminator loss is then simply $D(x) - D(G(z))$ and the generator loss is $D(G(z))$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <h2>Exercise 3.</h2>\n",
    "\n",
    "Write a training step for the generator using the cross entropy loss. The function definition is below. Fill in this missing components.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def train_generator(generator, discriminator_outputs, real_labels):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        generator: generator model object\n",
    "        discriminator_outputs: ouput of the discriminator on a set of values z, D(G(z))\n",
    "        real_labels: a vector of ones, size of discriminator_outputs\n",
    "        \n",
    "    Returns:\n",
    "        g_loss: generator loss\n",
    "    \"\"\"\n",
    "    generator.zero_grad()\n",
    "    #TODO: complete the code\n",
    "    # g_loss =\n",
    "    g_loss.backward()\n",
    "    g_optimizer.step()\n",
    "    return g_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# %load solutions/3_train_g.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Model training\n",
    "\n",
    "We'll now use our training functions in an iterative process over multiple epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Due to the adversarial nature of GAN training, the different losses often oscillate over training instead of converging over time as we see in other deep learning training methods. As such, it is advised to frequently save results during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare folder to store results\n",
    "if not os.path.exists('results'):\n",
    "    os.makedirs('results')\n",
    "    \n",
    "# Prepare folder to store models\n",
    "if not os.path.exists('models'):\n",
    "    os.makedirs('models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Draw samples from the input distribution to inspect the generation on training \n",
    "num_test_samples = 16\n",
    "test_noise = Variable(torch.randn(num_test_samples, 100))\n",
    "# Set number of epochs and initialize figure counter\n",
    "num_epochs = 4\n",
    "num_batches = len(train_loader)\n",
    "# Set counter\n",
    "num_fig = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Create figure for plotting\n",
    "size_figure_grid = int(math.sqrt(num_test_samples))\n",
    "fig, ax = plt.subplots(size_figure_grid, size_figure_grid, figsize=(6, 6))\n",
    "for i, j in itertools.product(range(size_figure_grid), range(size_figure_grid)):\n",
    "    ax[i,j].get_xaxis().set_visible(False)\n",
    "    ax[i,j].get_yaxis().set_visible(False)\n",
    "\n",
    "# Start training\n",
    "t0 = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    for n, (images, _) in enumerate(train_loader):\n",
    "\n",
    "        # Convert data to suitable format\n",
    "        images = Variable(images)\n",
    "        real_labels = Variable(torch.ones(images.size(0), 1))\n",
    "\n",
    "        # Sample from generator\n",
    "        noise = Variable(torch.randn(images.size(0), 100))\n",
    "        fake_images = generator(noise)\n",
    "        fake_labels = Variable(torch.zeros(images.size(0), 1))\n",
    "\n",
    "        # Train the discriminator\n",
    "        d_loss, real_score, fake_score = train_discriminator(\n",
    "            discriminator, images, real_labels, fake_images, fake_labels)\n",
    "\n",
    "        # Sample again from the generator and get output from discriminator\n",
    "        noise = Variable(torch.randn(images.size(0), 100))\n",
    "        fake_images = generator(noise)\n",
    "        outputs = discriminator(fake_images)\n",
    "\n",
    "        # Train the generator\n",
    "        g_loss = train_generator(generator, outputs, real_labels)\n",
    "\n",
    "        # Every half epoch generates pictures with to generator to monitor training\n",
    "        if (n+1) % int(num_batches/2) == 0:\n",
    "            # generate pictures\n",
    "            test_images = generator(test_noise)\n",
    "            # plot them\n",
    "            for k in range(num_test_samples):\n",
    "                i = k//4\n",
    "                j = k%4\n",
    "                ax[i,j].cla()\n",
    "                ax[i,j].imshow(test_images[k,:].data.cpu().numpy().reshape(28, 28),\n",
    "                               cmap='Greys')\n",
    "            display.clear_output(wait=True)\n",
    "            display.display(plt.gcf())\n",
    "\n",
    "            # save the picture\n",
    "            plt.savefig('results/mnist-gan-%03d.png'%num_fig)\n",
    "            num_fig += 1\n",
    "            # print log\n",
    "            print('Epoch [%d/%d], Step[%d/%d], d_loss: %.4f, g_loss: %.4f, '\n",
    "                  'D(x): %.2f, D(G(z)): %.2f, time %.2f min'\n",
    "                  % (epoch + 1, num_epochs, n+1, num_batches,\n",
    "                     d_loss.detach().numpy(), g_loss.detach().numpy(),\n",
    "                     real_score.detach().numpy().mean(),\n",
    "                     fake_score.detach().numpy().mean(), (time.time()-t0)/60))\n",
    "\n",
    "        # at the end of n epochs, save the models\n",
    "        if epoch % 2 == 0:\n",
    "            torch.save(generator.state_dict(),\n",
    "                    os.path.join('models', 'generator.pkl'))\n",
    "            torch.save(discriminator.state_dict(),\n",
    "                    os.path.join('models', 'discriminator.pkl'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
