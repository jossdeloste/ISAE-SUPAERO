# Generative Adversarial Networks

* [Home](https://supaerodatascience.github.io/deep-learning/)
* [Github repository](https://github.com/SupaeroDataScience/deep-learning/)

In this class, we introduce Generative Adversarial Networks, showing an example
of GAN training on MNIST.

[Notebook source](https://github.com/SupaeroDataScience/deep-learning/blob/main/GAN/Generative%20Adversarial%20Networks.ipynb)

[Notebook on Colab](https://colab.research.google.com/github/SupaeroDataScience/deep-learning/blob/main/GAN/Generative%20Adversarial%20Networks.ipynb)

## Additional Resources

DeepMind lecture on GANs which goes further in depth on GAN training, architectures, and applications.

<iframe width="560" height="315" src="https://www.youtube.com/embed/wFsI2WqUfdA" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

[2016 NeurIPS GAN tutorial](https://arxiv.org/pdf/1701.00160.pdf)

[Unrolling GANs](https://arxiv.org/pdf/1611.02163.pdf) which helps with reducing mode collapse and early convergence.

[Common Problems](https://developers.google.com/machine-learning/gan/problems) in GAN training.

[DCGAN Pytorch tutorial](https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html)

[CycleGAN](https://openaccess.thecvf.com/content_ICCV_2017/papers/Zhu_Unpaired_Image-To-Image_Translation_ICCV_2017_paper.pdf) - Zhu, Jun-Yan, et al. "Unpaired image-to-image translation using cycle-consistent adversarial networks." Proceedings of the IEEE international conference on computer vision. 2017. [code](https://junyanz.github.io/CycleGAN/)

<iframe width="560" height="315" src="https://www.youtube.com/embed/AxrKVfjSBiA" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

[StyleGAN](https://openaccess.thecvf.com/content_CVPR_2019/papers/Karras_A_Style-Based_Generator_Architecture_for_Generative_Adversarial_Networks_CVPR_2019_paper.pdf) - Karras, Tero, Samuli Laine, and Timo Aila. "A style-based generator architecture for generative adversarial networks." Proceedings of the IEEE conference on computer vision and pattern recognition. 2019.

<iframe width="560" height="315" src="https://www.youtube.com/embed/kSLJriaOumA" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

[This person does not exist](https://thispersondoesnotexist.com/) -
GAN-generated faces. ([cat version](https://thiscatdoesnotexist.com/))

[Everybody Dance Now](https://arxiv.org/pdf/1808.07371.pdf) demonstrates motion transfer in videos.

<iframe width="560" height="315" src="https://www.youtube.com/embed/PCBTZh41Ris" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

[Deepfakes](https://arxiv.org/pdf/2004.11138.pdf), the application of GANs and
other deep ANNs to creating modified or generated media, sometimes for harmful and deceptive purposes.

[ArtBreeder](https://artbreeder.com/) uses BigGAN and StyleGAN to generate
images in an iterative optimization process based on evolutionary algorithms.
[Ganbreeder](https://github.com/joel-simon/ganbreeder) is an open-source
version.

[The deep learning book](https://www.deeplearningbook.org/) is fully available
online and contains many great examples. Notebook versions of those examples are
available [here](https://github.com/hadrienj/deepLearningBook-Notes). [Chapter
20](https://www.deeplearningbook.org/contents/generative_models.html) covers
generative models and section 20.10.4 specifically covers GANs.
