{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was created by Josselin Deloste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:22pt; line-height:25pt; font-weight:bold; text-align:center;\">Collaborative Filtering in Recommender Systems</div>\n",
    "\n",
    "Recommender systems are omnipresent in most of your everyday consulted websites. Indeed you all have been recommanded either a movie to watch (on Netflix, Amazon prime), a song to listen (on Deezer or Spotify), an item to buy (Ebay, Amazon), a person to follow (Instagram, Facebook, Twitter). All of these approaches are the results of recommander systems which have obvious applications when it comes to maximize customer satisfaction by improving the service quality, providing easier navigation and/or to increase advertising campaign returns. \n",
    "\n",
    "\n",
    "$\\textbf{How do these companies do ?}$\n",
    "\n",
    "They use various techniques combining different datasets which are : \n",
    "- pure user datasets - only user informations e.g : location, profession, age, passions, interests etc ...\n",
    "- pure item datasets - only item informations e.g Movies : genre, year, actors, version etc ...\n",
    "- user-item datasets - user-item informations e.g : ratings etc ... \n",
    "- mixed datasets - a mix of the foregoing\n",
    "\n",
    "Recommender systems techniques relying only on user-item informations are known as $\\textit{collaborative filtering}$ methods. The following course aims to present the latter algorithms and to explain how $\\textit{collaborative filtering}$ approaches are used in recommender systems through easy examples. \n",
    "\n",
    "1. [Collaborative Filtering](#sec1)\n",
    "2. [Pratical case Introduction - The movieLens dataset](#sec2)\n",
    "3. [User based collaborative filtering](#sec3)\n",
    "4. [Item based collaborative filtering](#sec4)\n",
    "5. [Matrix factorization collaborative filtering](#sec5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. <a id=\"sec1\"></a>Collaborative Filtering (CF)\n",
    "\n",
    "**Idea:**\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"fig1.jpg\" width=\"600px\">  \n",
    "Word-of-mouth has always been one of the most powerful marketing tool ! Have you liked something recently ? It is highly likely that someone who has liked similar items will appreciate it too or that you would like a similar product ! The problem remains to evaluate the \"user-user or item-item similarity\".\n",
    "\n",
    "**Some notation:**\n",
    "- $M$ : rating matrix $M:=[m_{ui}]_{u,i\\in  [\\![1,n]\\!]^{2}}$ where $m_{ui}$ corresponds to the item $i$ rating given by user $u$\n",
    "\n",
    "Typical rating matrix:\n",
    "\\begin{equation}\n",
    "M \\in \\mathbb{R}^{m \\times n} = \\left [ \\begin{array}{cccccccc}\n",
    "0.5 & NaN & 2   & NaN & NaN & NaN & 5   & NaN \\\\\n",
    "NaN & 4   & NaN & NaN & 0.5 & 3   & 2   & 1   \\\\\n",
    "1   & 3   & 3   & NaN & NaN & 0.5 & 3   & 4   \\\\\n",
    "4   & 5   & 2   & 4   & 2   & NaN & 2.5 & NaN \\\\\n",
    "2   & NaN & 4   & 5   & 3.5 & NaN & NaN & 3   \\\\\n",
    "NaN & 2   & 3.5 & 0.5 & 2   & 3   & 2   & NaN \\\\\n",
    "3   & NaN & NaN & 5   & 4   & 0.5 & 3   & 4   \\\\\n",
    "1.5 & NaN & NaN & 2   & 3   & NaN & NaN & NaN \\\\\n",
    "NaN & 3   & 3   & NaN & 3.5 & NaN & 4   & 3   \\\\\n",
    "NaN & 2.5 & NaN & 4   & 4   & 3   & NaN & NaN \\\\\n",
    "\\end{array} \\right ]\n",
    "\\end{equation}\n",
    "\n",
    "$\\textit{Remark :}$ The rating matrix is a sparse matrix. Indeed in general by modifying our initial notation system, we can assume that unknown matrix entries are zeros (we just need not to allow 0 grades). \n",
    "\n",
    "In our example, $m:=10$ users have accepted to rate $n:=8$ items $\\textit{e.g}$ in this matrix user 1 has given a 0.5 note to item 1 and a 5 note to item 7. \n",
    "\n",
    "Collaborative Filtering aims to fill in the matrix using only existing values: we want to replace all remaining unknown values by approximations based on the available rates and not user or item features. Thus, these approximations will correspond to our recommendations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.<a id=\"sec2\"></a> Our practise case : Would you like to update your old-fashined movie recommending system ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{History:}$ \n",
    "\n",
    "Historically collaborative filtering had been substantially developped during Netflix early years when the company released a fully open $USD 1 000 000 prize money competition. At the end of the competition Netflix improves its recommendation satisfactions by 10 %.\n",
    "\n",
    "During this recommender system course we will study recommender algorithms through movie recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing needed libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100234, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>847117005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>847642142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3.0</td>\n",
       "      <td>847641896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>4.0</td>\n",
       "      <td>847642008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>4.0</td>\n",
       "      <td>847641956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     5.0  847117005\n",
       "1       1        2     3.0  847642142\n",
       "2       1       10     3.0  847641896\n",
       "3       1       32     4.0  847642008\n",
       "4       1       34     4.0  847641956"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load our ratings data\n",
    "ratings = pd.read_csv('./Movies_data/ratings.csv')\n",
    "\n",
    "print(ratings.shape)\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8927, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                   Adventure|Children|Fantasy  \n",
       "2                               Comedy|Romance  \n",
       "3                         Comedy|Drama|Romance  \n",
       "4                                       Comedy  "
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load our movies data\n",
    "movies = pd.read_csv('./Movies_data/movies.csv')\n",
    "\n",
    "print(movies.shape)\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movieId</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>132796</th>\n",
       "      <th>133419</th>\n",
       "      <th>133545</th>\n",
       "      <th>133897</th>\n",
       "      <th>134170</th>\n",
       "      <th>134368</th>\n",
       "      <th>134393</th>\n",
       "      <th>134783</th>\n",
       "      <th>134853</th>\n",
       "      <th>135887</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 8915 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "movieId  1       2       3       4       5       6       7       8       \\\n",
       "userId                                                                    \n",
       "1           5.0     3.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2           3.0     3.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "3           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "4           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "5           4.0     0.0     0.0     0.0     3.0     4.0     0.0     0.0   \n",
       "\n",
       "movieId  9       10       ...    132796  133419  133545  133897  134170  \\\n",
       "userId                    ...                                             \n",
       "1           0.0     3.0   ...       0.0     0.0     0.0     0.0     0.0   \n",
       "2           0.0     0.0   ...       0.0     0.0     0.0     0.0     0.0   \n",
       "3           0.0     0.0   ...       0.0     0.0     0.0     0.0     0.0   \n",
       "4           0.0     0.0   ...       0.0     0.0     0.0     0.0     0.0   \n",
       "5           0.0     0.0   ...       0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "movieId  134368  134393  134783  134853  135887  \n",
       "userId                                           \n",
       "1           0.0     0.0     0.0     0.0     0.0  \n",
       "2           0.0     0.0     0.0     0.0     0.0  \n",
       "3           0.0     0.0     0.0     0.0     0.0  \n",
       "4           0.0     0.0     0.0     0.0     0.0  \n",
       "5           0.0     0.0     0.0     0.0     0.0  \n",
       "\n",
       "[5 rows x 8915 columns]"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating our rating matrix\n",
    "M = ratings.pivot(index = \"userId\", columns = \"movieId\", values = \"rating\").fillna(0)\n",
    "movie_Ids_columns = M.columns\n",
    "M.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lines (i.e total number of users) in the matrix M : 718\n",
      "Number of columns (i.e total number of movies) in the matrix M : 8915\n"
     ]
    }
   ],
   "source": [
    "M = np.array(M)\n",
    "\n",
    "print('Number of lines (i.e total number of users) in the matrix M : '+str(M.shape[0]))\n",
    "print('Number of columns (i.e total number of movies) in the matrix M : '+str(M.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, zero values correspond to unknown ratings : it is not possible to provide a note smaller than 0.5. The rating range between 0.5 and 5.0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The initial sparsity percentage of the M matrix is: 98.43408108458563\n",
      "The new matrix M shape is: (718,8915)\n",
      "The new matrix M shape is: (718,8915)\n",
      "The new sparsity percentage of the M matrix is: 98.43408108458563\n"
     ]
    }
   ],
   "source": [
    "# print M sparsity percentage\n",
    "print('The initial sparsity percentage of the M matrix is: '+str(sum(sum(M==0))/(M.shape[0]*M.shape[1])*100))\n",
    "\n",
    "# Delete all movies for which we do not have any data and therefore which we would not be able to recommend\n",
    "valid_movies = (M!=0).sum(axis=0) > 0 # we collect all movie indexes corresponding to movies rated at least once \n",
    "M = M[:,valid_movies]\n",
    "print('The new matrix M shape is: ('+str(M.shape[0])+','+str(M.shape[1])+')')\n",
    "\n",
    "# Exercice delete all users for who we do not have any data and therefore who will not be able to use the recommending service\n",
    "valid_users = (M!=0).sum(axis=1)>0 \n",
    "M = M[valid_users,:]        \n",
    "print('The new matrix M shape is: ('+str(M.shape[0])+','+str(M.shape[1])+')')\n",
    "\n",
    "print('The new sparsity percentage of the M matrix is: '+str(sum(sum(M==0))/(M.shape[0]*M.shape[1])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some basic statistics\n",
    "\n",
    "# average rating given by each user\n",
    "user_means = np.array([M[i,M[i,:]!=0].mean() for i in range(M.shape[0])])\n",
    "\n",
    "# movie average rate \n",
    "movie_means = np.array([M[M[:,i]!=0,i].mean() for i in range(M.shape[1])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Count')"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# User means histogram\n",
    "plt.hist(user_means, bins=20)\n",
    "plt.xlabel(\"Mean User Rating\")\n",
    "plt.ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Count')"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Movie means histogram\n",
    "plt.hist(movie_means, bins=20)\n",
    "plt.xlabel(\"Mean Movie Rating\")\n",
    "plt.ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Number of Movies')"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Number of reviews per movie histogram\n",
    "num_reviews = (M!=0).astype(float).sum(axis=0)\n",
    "plt.hist(num_reviews,bins=np.logspace(np.log10(min(num_reviews)),np.log10(max(num_reviews)),10))\n",
    "plt.gca().set_xscale(\"log\")\n",
    "plt.xlabel(\"Number of Reviews\")\n",
    "plt.ylabel(\"Number of Movies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Note:}$ Using a first trivial approach, for each user we can already return the best rated movie which has not been watched yet. But let us personalize our recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. <a id=\"sec3\"></a> User-user collaborative filtering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{History:}$ \n",
    "\n",
    "User-user collaborative filtering also known as k-NN collaborative filtering was the first of the automated CF methods. \n",
    "\n",
    "<img src=\"user_user_approach.png\" width=\"300px\">  \n",
    "\n",
    "** Idea:**\n",
    "- The active user's preference can be predicted using other selected and aggregated users' opinions \n",
    "\n",
    "** Challenges:**\n",
    "\n",
    "The collaborative filtering requires a similarity function $s :  U^{2} \\rightarrow \\mathbb{R}$ which will compute the similarity between two users. One idea is to use correlation coefficients or other similarity measurement coefficients. This solution raises several issues related to low level of available data : How to compute similarities when only a few common data are available ? \n",
    "\n",
    "** Computing predictions:**\n",
    "\n",
    "In order to generate our predictions for a given user $u$ we first need to find a neighborhood $N \\in U$. Then for all unrated items $i$ we need to compute user $u$ predictions. To do so a commonly used method consist in computing the weighted average : \n",
    "\n",
    " <center> $\\widehat{m}_{ui} := \\overline{m_{u}} + \\frac{\\sum_{u_{n} \\in N}s(u,u_{n})*(m_{u_{n},i}-\\overline{m_{u_{n}}})}{\\sum_{u_{n} \\in N}|s(u,u_{n}|}$ \n",
    "\n",
    "with $s(.,.)$ the user similarity function, $N$ user $u$ neighbors, $\\overline{m_{u}}$ the average rate given by user $u$ and $\\widehat{m}_{ui}$ the estimated rating that user $u$ would give for item $i$ \n",
    "\n",
    "** Computing User Similarity:**\n",
    "\n",
    "One critical design decision is to choose the appropriate similarity function.\n",
    "\n",
    "Only the most common functions will be presented:\n",
    "\n",
    "\n",
    "-** Person correlation:** We compute Person's statistical correlation between user's ratings.\n",
    "\n",
    "<center>$s(u,u_{n}):= \\frac{\\sum_{i \\in I_{u} \\cap I_{u_{n}}}(m_{ui} - \\overline{m_{u}})(m_{u_{n}i} - \\overline{m_{u_{n}}})}{\\sqrt{\\sum_{i \\in I_{u} \\cap I_{u_{n}}}(m_{ui} - \\overline{m_{u}})^{2}}\\sqrt{\\sum_{i \\in I_{u} \\cap I_{u_{n}}}(m_{u_{n}i} - \\overline{m_{u_{n}}})^{2}}}$\n",
    "\n",
    "In order to improve our similarity accuracy we can define a value number threshold under which the similarity function will not computed. Indeed in a two common values case the Person's correlation will exactly be either -1 or 1. In addition it is also possible to scale the similarity when the number of co-rated items falls below a defined threshold. To do so we simply multiply the similarity function by min{$\\frac{|I_{u}\\cap I_{u_{n}}|}{Threshold}$,1}.\n",
    "\n",
    "\n",
    "-** Constrained Person correlation:** We compute a constrained Person's correlation between user's ratings.\n",
    "\n",
    "Historically introduced by the singer Ringo who solicited ratings from its users on a 7-point scale : 1 hate, 7 love and 4 corresponds to a neutral value noted $m_{n}$ $\\textit{i.e}$ the user neither like nor dislike. It is then possible to correlate absolute like/dislike rather than relative deviation as for the standard Person's correlation coefficient. \n",
    "\n",
    "<center> $s(u,u_{n}):= \\frac{\\sum_{i \\in I_{u} \\cap I_{u_{n}}}(m_{ui} - m_{n})(m_{u_{n}i} - m_{n})}{\\sqrt{\\sum_{i\\in I_{u} \\cap I_{u_{n}}(m_{ui} - m_{n})^{2}}}\\sqrt{\\sum_{i\\in I_{u} \\cap I_{u_{n}}(m_{u_{n}i} - m_{n})^{2}}}}$\n",
    "    \n",
    "    \n",
    "-** Spearman rank correlation:** Computing Spearman's correlation. \n",
    "\n",
    "Same principle as for Person's correlation : we just use Spearman's rank correlation instead of Person's coefficient (by definition the Spearman coefficient is defined as the Person coefficient applied to rank variables).\n",
    "\n",
    "<center> $s(u,u_{n}):= 1 - \\frac{6\\sum d_{u u_{n}i}^{2}}{n(n^{2}-1)}$ \n",
    "    \n",
    "with $n := |I_{u}\\cap I_{u_{n}}|$ and $d_{i}:= rank(m_{ui}) - rank(m_{u_{n}i})$\n",
    "    \n",
    "    \n",
    "-** Cosine similarity:**  Computing cosine similarity. \n",
    "\n",
    "We now use a linear algebra based approach instead of a statistical approach : Users are represented as $|I|$-dimensional vectors and the similarity is measured by the cosine distance between two rating vectors.\n",
    "\n",
    "<center>$s(u,u_{n}):= \\frac{m_{u}.m_{u_{n}}}{||m_{u}||_{2}||m_{u_{n}}||_{2}} = \\frac{\\sum_{i}m_{ui}m_{u_{n}i}}{\\sqrt{\\sum_{i}m_{ui}^{2}}\\sqrt{\\sum_{i}m_{u_{n}i}^{2}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">**Exercice**<br>\n",
    "Can you predict user rates ?\n",
    "\n",
    "Given data :\n",
    "<ul>\n",
    "<li> Rating matrix : $M$\n",
    "<li> User means : user_means\n",
    "<li> Similarity matrix : $S$\n",
    "<li> UserId : $u$\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/code1.py\n",
    "### WRITE YOUR CODE HERE\n",
    "# If you get stuck, uncomment the line above to load a correction in this cell (then you can execute this code)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">**Exercice**<br>\n",
    "Can you generate the similarity matrix using the desired method (Person/Spearman correlations or Cosine similarity)?\n",
    "\n",
    "Given data :\n",
    "<ul>\n",
    "<li> Rating matrix : $M$\n",
    "<li> User means : user_means\n",
    "<li> Common threshold : $common\\_items\\_threshold$ \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/code2.py\n",
    "### WRITE YOUR CODE HERE\n",
    "# If you get stuck, uncomment the line above to load a correction in this cell (then you can execute this code)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">**Exercice**<br>\n",
    "Can you generate user 4 top 10 recommendations ?\n",
    "\n",
    "Given data :\n",
    "<ul>\n",
    "<li> Rating matrix : $M$\n",
    "<li> User means : user_means\n",
    "<li> Similarity matrix : $S$ - compute it using your desired method $\\textit{e.g}$ cosine similarity\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/code3.py\n",
    "### WRITE YOUR CODE HERE\n",
    "# If you get stuck, uncomment the line above to load a correction in this cell (then you can execute this code)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. <a id=\"sec4\"></a> Item-Item collaborative filtering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"item_item_approach.png\" width=\"300px\">  \n",
    "\n",
    "** Idea:**\n",
    "- If one user has liked an item he/she will probably appreciate similar items.\n",
    "\n",
    "\n",
    "** Computing neighborhood:**\n",
    "In order to estimate user $u$ rating for item $i$, we use all other user $u$ ratings weighted by the similarity between the two items. Thus the recommender system remains unchanged excepted for the similarities which are now calculated using an item similarity function.\n",
    "\n",
    " <center> $\\widehat{m}_{ui} := \\overline{m_{i}} + \\frac{\\sum_{i_{n} \\in N}s(i,i_{n})*(m_{ui_{n}}-\\overline{m_{i_{n}}})}{\\sum_{i_{n} \\in N}|s(i,i_{n}|}$ \n",
    "\n",
    "with $s(.,.)$ the item similarity function, $\\overline{m_{i}}$ the average rate given for item $i$ and $\\widehat{m}_{ui}$ the estimated rating that user $u$ would give for item $i$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">**Exercice**<br>\n",
    "Can you predict movie rates?\n",
    "\n",
    "Given data :\n",
    "<ul>\n",
    "<li> Rating matrix : $M$\n",
    "<li> Movie means : item_means\n",
    "<li> Similarity matrix : $S$\n",
    "<li> MovieId : $i$\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/code4.py\n",
    "### WRITE YOUR CODE HERE\n",
    "# If you get stuck, uncomment the line above to load a correction in this cell (then you can execute this code)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">**Test**<br>\n",
    "Generate item 10 rate predictions\n",
    "\n",
    "Given data :\n",
    "<ul>\n",
    "<li> Rating matrix : $M$\n",
    "<li> Movie means : movie_means\n",
    "<li> Similarity matrix : $S$ - compute it using your desired method $\\textit{e.g}$ cosine similarity\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/code5.py\n",
    "### WRITE YOUR CODE HERE\n",
    "# If you get stuck, uncomment the line above to load a correction in this cell (then you can execute this code)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">**Question**<br>\n",
    "How would you realize user 4 top 10 recommendations ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\"><a href=\"#answer2\" data-toggle=\"collapse\">**Ready to see the answer? (click to expand)**</a><br>\n",
    "<div id=\"answer2\" class=\"collapse\">\n",
    "To get a list of a user predictions, we need to iterate over all items $\\textit{i.e}$ for the entire rating matrix $M$.\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">**Optional**<br>\n",
    "Generate user 4 top 10 recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/code6.py\n",
    "### WRITE YOUR CODE HERE\n",
    "# If you get stuck, uncomment the line above to load a correction in this cell (then you can execute this code)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Conclusion:**\n",
    "\n",
    "The recommendations are slightly differents. It would be interesting to know which one works varying the similarity function. For both approaches we do not scale particularly well massive datasets because of the rating matrix sparsity (computing time increases heavily $\\textit{cf.}$ item-item approach for which we had to realize all possible predictions). In addition when we match to sparse low-level details we assume that the user's preference is well represented which may be false (if one user has listened a dozen of Eminem songs and another has listened a dozen different ones they will have nothing in common even if it seems pretty obvious they share preferences). Finally neighbors are not independent at all, so using a standard similarity metric to define a weighted mean overcounts information $\\textit{e.g}$ if both users have watched Harry Potter movies we will count 8 times the same information. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. <a id=\"sec5\"></a> Matrix factorization collaborative filtering (Singular Value Decomposition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How can we resolve previous challenges ?** \n",
    "\n",
    "One solution is to derive users' tastes and preferences directly from the data. By using the Matrix factorization collaborative filtering which fits better into the machine learning framework and does not rely on the idea of \"nearness\" we will \"learn\" users' tastes. \n",
    "\n",
    "** Idea:**\n",
    "-  \n",
    "Matrix factorization is the breaking down of one matrix in a product of multiple matrices. The goal is to learn the  users' preferences and items' attributes from known ratings in order to predict all missing ratings. In orther words we want to find a smaller number of dimensions, ideally a constant number so that items and users can be represented by $k$-dimensional vectors.\n",
    "\n",
    "**Advantages:**\n",
    "\n",
    "By doing a matrix factorization we rebuild our rating matrix in a lower-rank one which saves memory space(In general rating matrices are large sparse matrices). In addition in this case we will be able to generate recommendations for new users who have not rated any movie.\n",
    "\n",
    "**Singular Value Decomposition example:**\n",
    "\n",
    "To start with the easiest matrix factorization may be singular value decomposition - SVD : it decomposes a matrix $M$ into the best lower rank approximation matrix. \n",
    "\n",
    "<center> $ M = U \\Sigma T^{T}$\n",
    "    \n",
    "with $U$ and $T^{T}$ othogonal matrices and $\\Sigma$ the singular value matrix. $\\Sigma$ represents the movie features matrix, U represents the user feature preferences and $T^{T}$ the movie feature relevancies. \n",
    "\n",
    "<img src=\"fig2.png\" width=\"300px\">  \n",
    "\n",
    "\n",
    "**Dimension reduction:**\n",
    "\n",
    "In order to reduce the approximation rank, we want to keep only the top features which underly users' tastes and preferences. In pratice one way to do so is to select a reasonable number of features that will be used and then to minimize the Root-mean-square error RMSE. That's equivalent of resolving a classical optimization algorithms finding the best lower approximation possible.\n",
    "\n",
    "With SVD decomposition we just have to choose the desired number of features $k$ and it gives directly the corresponding decomposition. Indeed first we realize a non-reduced SVD decomposition (possible for all matrices) and then select the $k$ highest singular values and dump the others. \n",
    "\n",
    "**Computing predictions:**\n",
    "\n",
    "Once the SVD reduction is computed the predicted preference or rating of user $u$ for movie/item $i$ can be computed as the dot product of the user interest vector $\\textbf{u}$ and the movie/topic relevance vector $t$:\n",
    "\n",
    "<center> $\\widehat{m_{ui}} = \\sum_{f}u_{f}d_{f}t_{f}$\n",
    "\n",
    "$d_{f}$ represents the movie feature importances obtained thanks the singular value $D$. Indeed with a SVD decomposition we generate our predictions using a weighted dot product.\n",
    "\n",
    "$\\textit{Remark:}$ The matrix factorization for collaborative filtering is quite close from the Principal component analysis decomposition (PCA) used in unsupervized learning. In both case we want to find a matrix low-rank approximation. However while with PCA we try to find an approximation that matches all $M$ entries with matrix factorization for CF we only consider observed entry losses. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">**Question**<br>\n",
    "Generate all predicted rating using SVD matrix factorization\n",
    "\n",
    "$\\textbf{Help:}$ see svds notice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/code7.py\n",
    "### WRITE YOUR CODE HERE\n",
    "# If you get stuck, uncomment the line above to load a correction in this cell (then you can execute this code)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_movies(predictions_df, userID, movies_df, original_ratings_df, num_recommendations=5):\n",
    "    # Get and sort the user's predictions\n",
    "    user_row_number = userID - 1 # UserID starts at 1, not 0\n",
    "    sorted_user_predictions = predictions_df[user_row_number].sort_values(ascending=False) # UserID starts at 1\n",
    "    # Get the user's data and merge in the movie information.\n",
    "    user_data = original_ratings_df[original_ratings_df.userId == (userID)]\n",
    "    user_full = (user_data.merge(movies_df, how = 'left', left_on = 'movieId', right_on = 'movieId').\n",
    "                     sort_values(['rating'], ascending=False))\n",
    "    # Recommend the highest predicted rating movies that the user hasn't seen yet.\n",
    "    temp = pd.DataFrame(sorted_user_predictions).reset_index()\n",
    "    temp.columns = ['movieId','rating']\n",
    "    recommendations = (movies_df[~movies_df['movieId'].isin(user_full['movieId'])].\n",
    "         merge(temp, how = 'left',left_on = 'movieId',right_on = 'movieId').rename(columns = {user_row_number: 'predictions'}).\n",
    "         sort_values('rating', ascending = False).iloc[:num_recommendations, :-1])\n",
    "    print('User '+str(userID)+' has already rated '+ str(user_full.shape[0]) +' movies')\n",
    "    print('Recommending highest '+str(num_recommendations) + ' predicted ratings movies not already rated :')\n",
    "    return user_full, recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 4 has already rated 24 movies\n",
      "Recommending highest 10 predicted ratings movies not already rated :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>61</td>\n",
       "      <td>Eye for an Eye (1996)</td>\n",
       "      <td>Drama|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>454</td>\n",
       "      <td>Firm  The (1993)</td>\n",
       "      <td>Drama|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>437</td>\n",
       "      <td>Cops and Robbersons (1994)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>102</td>\n",
       "      <td>Mr. Wrong (1996)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>185</td>\n",
       "      <td>Net  The (1995)</td>\n",
       "      <td>Action|Crime|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>246</td>\n",
       "      <td>Hoop Dreams (1994)</td>\n",
       "      <td>Documentary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>129</td>\n",
       "      <td>Pie in the Sky (1996)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>188</td>\n",
       "      <td>Prophecy  The (1995)</td>\n",
       "      <td>Fantasy|Horror|Mystery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>122</td>\n",
       "      <td>Boomerang (1992)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>71</td>\n",
       "      <td>Fair Game (1995)</td>\n",
       "      <td>Action</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     movieId                       title                  genres\n",
       "54        61       Eye for an Eye (1996)          Drama|Thriller\n",
       "397      454            Firm  The (1993)          Drama|Thriller\n",
       "381      437  Cops and Robbersons (1994)                  Comedy\n",
       "90       102            Mr. Wrong (1996)                  Comedy\n",
       "159      185             Net  The (1995)   Action|Crime|Thriller\n",
       "214      246          Hoop Dreams (1994)             Documentary\n",
       "113      129       Pie in the Sky (1996)          Comedy|Romance\n",
       "162      188        Prophecy  The (1995)  Fantasy|Horror|Mystery\n",
       "107      122            Boomerang (1992)          Comedy|Romance\n",
       "64        71            Fair Game (1995)                  Action"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate user 4  top 10 recommendations\n",
    "already_rated,recommendations = recommend_movies(preds,4,movies,ratings,10)\n",
    "recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Non-Negative Matrix Factorization example**\n",
    "\n",
    "Another MF commonly used is the non-negative matrix factorization : we approximate the non negative rating matrix M as a product of two non negative lower rank matrices. \n",
    "\n",
    "$\\textit{Remark:} We can assume M is positive with no loss of generality as the rating scale can be defined in order not to have negative rates.\n",
    "\n",
    "<center> $M = UT^{T}$\n",
    "    \n",
    "The $U$ & $T^{T}$ matrices' interpretentation remain unchanged : U represents the user feature preferences and T the movie feature relevancies.\n",
    "\n",
    "<img src=\"fig3.png\" width=\"400px\"> \n",
    "\n",
    "**Dimension reduction:**\n",
    "\n",
    "As explained previously, in order to reduce the matrix dimensions we choose a desired number of features $k$ and then minimize the squared loss function\n",
    "\n",
    "<center> $minimize_{u_{1:m},t_{1:n}} \\sum_{ui \\in S} (u_{u}t^{T}_{i} - M_{ui})^{2}$\n",
    "\n",
    "To solve this optimization problem, a common practice is to use the $\\textit{alternating least squares algorithm}$ or $\\textit{gradient descent algorithm}$. \n",
    "\n",
    "$\\textit{Remark:}$ \n",
    "If we do not want to define a number of features $k$ we can minimize a slightly modified loss function : \n",
    "<center> $minimize_{u_{1:m},t_{1:n}} \\sum_{ui \\in S} (u_{u}t^{T}_{i} - M_{ui})^{2} + \\lambda (||u_{u}||_{1} + ||t_{i}||_{1})$\n",
    "\n",
    "$\\lambda (||u_{u}||_{1} + ||t_{i}||_{1})$ represents the regularization term. As we have seen during the unsupervized learning courses the convex hull of the counting function is exactly the $||.||_{1}$ norm. \n",
    "\n",
    "** Computing predictions:**\n",
    "\n",
    "The prediction $\\widehat{mui}$ is once more given by :\n",
    "\n",
    "<center>  $\\widehat{m_{ui}}= u_{u}t_{i}^{T}$\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">**Question**<br>\n",
    "- Generate all predicted rating using Non-Negative Matrix Factorization (NMF)\n",
    "- Generate user 4  top 10 recommendations\n",
    "\n",
    "\n",
    "$\\textbf{Help:}$ see NMF notice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "# %load solutions/code8.py\n",
    "### WRITE YOUR CODE HERE\n",
    "# If you get stuck, uncomment the line above to load a correction in this cell (then you can execute this code)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
