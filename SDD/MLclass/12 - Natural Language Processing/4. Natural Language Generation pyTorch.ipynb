{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:22pt; line-height:25pt; font-weight:bold; text-align:center;\">Natural Language Generation</div>\n",
    "\n",
    "In this exercice, we will try out the approach of Natural Language Generation, using a Seq2Seq (sequence to sequence) architecture.\n",
    "\n",
    "This notebook is a variant of the 3rd notebook on Natural Language Generation, using pyTorch instead of Keras/TF.\n",
    "It is an adaptation of the excellent pyTorch tutorial on Seq2Seq approaches.\n",
    "\n",
    "Natural Language Generation has often used approaches close to \"fill-in-the-blanks\" templates. \n",
    "Seq2Seq Encoder-Decoder architectures make the issue of Natural Language Generation different, especially in the case of language translation.\n",
    "\n",
    "The approach is the following :\n",
    "1. A LSTM network encodes the input sequence into state vectors, with a predefined dimensionality\n",
    "2. A decoder LSTM predicts the next token of a target sequence based on the beginning o the sequence. The initial state is given by the encoder.\n",
    "\n",
    "The approach used here to train a system that predicts the next token based on the beginning of the sequence is called Teacher Forcing\n",
    "\n",
    "# 1. Parameters of the experiment\n",
    "\n",
    "In this example, we will train a system that translates basic english sentences into french. The data used for this example is a list of French sentences and their translation into english.\n",
    "\n",
    "# 1. Teacher forcing\n",
    "\n",
    "## 1.a Example\n",
    "\n",
    "Say we work with the following sequence :\n",
    "\n",
    "```\n",
    "Rien ne sert de courir il faut partir à point\n",
    "```\n",
    "\n",
    "We want to train a model that predicts the following word of the sequence based on the start of it. First, in order for the first word of the sequence and the end of it to be predicted, we need to add beginning and end tokens to the sequence. We decide to use \\t as the beginning token, and \\n as the end one :\n",
    "\n",
    "```\n",
    "\\t Rien ne sert de courir il faut partir à point \\n\n",
    "```\n",
    "\n",
    "When training the system, we start by inputing the \"\\t\" beginning token:\n",
    "\n",
    "```\n",
    "input: \n",
    "\\t\n",
    "prediction:\n",
    "sert\n",
    "```\n",
    "\n",
    "The untrained model generated \"sert\" where we expected \"Mary\". There are now two options to continue :\n",
    "\n",
    "### Without forcing :\n",
    "\n",
    "We add the previous output, \"sert\", to the input sequence, and continue generating :\n",
    "\n",
    "```\n",
    "input: \n",
    "\\t sert\n",
    "```\n",
    "\n",
    "With this approach, the error will propagate and make the model much slower to learn. \n",
    "\n",
    "### With teacher forcing\n",
    "\n",
    "After computing error, we discard the output \"sert\", and replace it with the word that was actually expected (\"Rien\"). This is called *teacher forcing* :\n",
    "\n",
    "```\n",
    "input: \n",
    "\\t Rien\n",
    "```\n",
    "\n",
    "Using his technique provides much faster training of the model. However, please note that it can also be a source of instability on previously unseen data.\n",
    "\n",
    "# 2. Importing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device used is  cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "hidden_size = 256  # Latent dimensionality of the encoding space.\n",
    "\n",
    "# Path to the data\n",
    "data_path = 'datasets/enfratexts.txt'\n",
    "\n",
    "#setting up device for use with pyTorch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device used is \",device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Utils to import and preprocess data\n",
    "\n",
    "We vectorize the data using words as features. \n",
    "\n",
    "This means that we will first define a vocabulary containing all the words in our corpus (simalr to what we did in notebook 1 for BOW and TFIDF calculation). The sequences will then be vectorized as a sequence of ints, corresponding to the id a given word in the dictionnary.\n",
    "\n",
    "This section defines a set of utilities to import data :\n",
    "- A class defining the characteristics of the languages imported (french and english), including the size of the vocabulary and the dictionnary mapping words to indexes.\n",
    "- Methods to import data, including a simple preprocessing that lowercases all the characters and removes special characters, in order to control the size of our dictionnay (see notebook 1). \n",
    "- Methods to select data from our dataset, useful for running iterations of our network.\n",
    "\n",
    "Please note that contrary to what we did for classification, the preprocessing does not include Lemmatization or Stemming. This is logical, considering we need to keep data readable by a human. \n",
    "And also don't forget that we are using two special characters \"1\" for start of sequence and \"0\" for end of sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start and end sequence tokens\n",
    "Start_sentence_token = 1\n",
    "End_sentence_token = 0\n",
    "\n",
    "\n",
    "#Class defining a language.\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}#Contains the index of each word in the dictionnary\n",
    "        self.word2count = {}#Contains the count of each word\n",
    "        self.index2word = {1: \"SOS\", 0: \"EOS\"} #Reverse lookup table for words (useful for decoding sentences back to a readable form)\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "            \n",
    "            \n",
    "## UTILS\n",
    "import re, unicodedata\n",
    "\n",
    "# Convert to ASCII (because of french sentences)\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Trim, lowercase sentences and remove special chracters except punctuation\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "# Filter data to keep only some relevant pairs. In particular, to ensure that the system trains fast enough,\n",
    "# we define a max length for sequences and keep only sentences sentences that start the same.\n",
    "max_length = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < max_length and len(p[1].split(' ')) < max_length and p[0].startswith(eng_prefixes)\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "\n",
    "# Reading, Normalizing data\n",
    "def readLangs(lang1, lang2):\n",
    "    print(\"Reading lines...\")\n",
    "    # Read the file and split into lines\n",
    "    lines = open(data_path, encoding='utf-8').read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "    \n",
    "    # Create language objects\n",
    "    input_lang = Lang(lang1)\n",
    "    output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "\n",
    "# Full pipeline for importing data :\n",
    "# Reads the files, and cleans data\n",
    "# Filters pairs of english/french sentences to keep only those that are short enough and start the same\n",
    "def prepareData(lang1, lang2):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Filtered to %s sentence pairs\" % len(pairs))\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Dictionnary size:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Import and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 170651 sentence pairs\n",
      "Filtered to 12761 sentence pairs\n",
      "Dictionnary size:\n",
      "english 3054\n",
      "francais 4740\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('english', 'francais')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Vectorizing the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous section we defined a dictionnary to vectorize data in a BOW fashion. \n",
    "\n",
    "Vectorizing data for use by our Neural Network is performed through the folowing steps :\n",
    "- Step 1 : using the dictionnary, the sequence of words is turned into a sequence of indexes\n",
    "- Step 2 : we append the End of Sentence token. Then, the sequence of indexes is turned into a tensor for use by pyTorch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1\n",
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "# STEP 2\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(End_sentence_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "# Performing the two steps of vectorization on a pair of english/french sequences\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0. Defining the Encoder-Decoder Architecture\n",
    "\n",
    "## 3.1. Encoder\n",
    "\n",
    "Encoding is performed via a LSTM, whose state we will store to condition the decoding. \n",
    "Inputs are first embedded into fixed dimensional space, and then encoded by the lstm. We also keep the hidden states of the lstm, as we need to feed them to the encoder for the next iteration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        #Embedding Layer\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        #LSTM Layer\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size)\n",
    "        \n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        \n",
    "        #Embedding the input\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        # We feed the embedded vector as well as the hidden states passed as argument into the lstm\n",
    "        output, hidden = self.lstm(output, hidden)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Decoder\n",
    "\n",
    "The decoder is meant to predict the next token of the target sentence, knowing the current token and the context vectors given by the encoder (hidden vectors).\n",
    "The context vectors ancode the input sequence that was given, and will condition all the prediction of the decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        #Embedding Laeyr\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        #LSTM Layer\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size)\n",
    "        #Linear layer mapping to the output size\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        \n",
    "        #Embedding the input and applying relu\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        \n",
    "        # We feed the embedded vector as well as the context vector passed as argument into the lstm\n",
    "        output, hidden = self.lstm(output, hidden)\n",
    "        # Softmax layer (probabilities of each token)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        \n",
    "        return output, hidden\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Training the model\n",
    "\n",
    "First, we write a function that defines one step of training the model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=max_length):\n",
    "    \n",
    "    #initialize hidden and cell state of the encoder lstm randomly\n",
    "    encoder_hidden = torch.randn(1, 1, hidden_size)\n",
    "    encoder_cell = torch.randn(1, 1, hidden_size)\n",
    "\n",
    "    #zero out the gradients\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    #Get length of input and target sequences\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    loss = 0\n",
    "    \n",
    "    ## ENCODER\n",
    "    #initialize the output of the encoder to zero\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    #We pass each input token to the encoder. At each step, we retrive the output and the hidden/cell states,\n",
    "    #forming the context vector. The context vector is fed back to the encoder for the next step.\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, (encoder_hidden,encoder_cell) = encoder(input_tensor[ei], (encoder_hidden,encoder_cell))\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    ## DECODER\n",
    "    #For the decoder, the input is initialized with a Start of Sequence token\n",
    "    decoder_input = torch.tensor([[Start_sentence_token]], device=device)\n",
    "\n",
    "    #The decoder states are initialized by passing the context vector from the encoder\n",
    "    decoder_hidden = encoder_hidden\n",
    "    decoder_cell = encoder_cell\n",
    "    \n",
    "    #We pass each target token to the decoder. We keep the hidden and cell states, that we will feed back to the\n",
    "    #decoder for the next step. However, the outputs are discarded, and the next input of the decoder is the target\n",
    "    #output (see teacher forcing above)\n",
    "    for di in range(target_length):\n",
    "        decoder_output, (decoder_hidden,decoder_cell) = decoder(decoder_input, (decoder_hidden,decoder_cell))\n",
    "        loss += criterion(decoder_output, target_tensor[di])\n",
    "        decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    #Backward prop\n",
    "    loss.backward()\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    #Return loss\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Plotting loss\n",
    "\n",
    "We have setup the trainign function to return the current loss of the model. \n",
    "The function below displays the learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Running multiple iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    \n",
    "    plot_losses = [] #Will hold all losses for plotting\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    #Setup optimizers\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    \n",
    "    #Prepare n_iter training data to run n-iter steps\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs)) for i in range(n_iters)]\n",
    "    \n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    \n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        \n",
    "        # Retrieve the next tensors for input and target\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "        \n",
    "        #Run one step of training\n",
    "        loss = train(input_tensor, target_tensor, encoder,decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        #Every few steps, we print the current status of training. We also store the loss for plotting\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('(iteration %d %d%%) loss = %.4f' % (iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    #Plot learning curve at the end\n",
    "    showPlot(plot_losses)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(iteration 1000 1%) loss = 4.3580\n",
      "(iteration 2000 2%) loss = 3.5869\n",
      "(iteration 3000 4%) loss = 3.3769\n",
      "(iteration 4000 5%) loss = 3.1932\n",
      "(iteration 5000 6%) loss = 3.0266\n",
      "(iteration 6000 8%) loss = 2.9167\n",
      "(iteration 7000 9%) loss = 2.7993\n",
      "(iteration 8000 10%) loss = 2.7012\n",
      "(iteration 9000 12%) loss = 2.6363\n",
      "(iteration 10000 13%) loss = 2.5246\n",
      "(iteration 11000 14%) loss = 2.4395\n",
      "(iteration 12000 16%) loss = 2.4261\n",
      "(iteration 13000 17%) loss = 2.3700\n",
      "(iteration 14000 18%) loss = 2.3195\n",
      "(iteration 15000 20%) loss = 2.2809\n",
      "(iteration 16000 21%) loss = 2.1337\n",
      "(iteration 17000 22%) loss = 2.1534\n",
      "(iteration 18000 24%) loss = 2.0646\n",
      "(iteration 19000 25%) loss = 2.0489\n",
      "(iteration 20000 26%) loss = 2.0235\n",
      "(iteration 21000 28%) loss = 1.9572\n",
      "(iteration 22000 29%) loss = 1.9466\n",
      "(iteration 23000 30%) loss = 1.9160\n",
      "(iteration 24000 32%) loss = 1.8492\n",
      "(iteration 25000 33%) loss = 1.8286\n",
      "(iteration 26000 34%) loss = 1.7288\n",
      "(iteration 27000 36%) loss = 1.6758\n",
      "(iteration 28000 37%) loss = 1.7280\n",
      "(iteration 29000 38%) loss = 1.7026\n",
      "(iteration 30000 40%) loss = 1.6543\n",
      "(iteration 31000 41%) loss = 1.5557\n",
      "(iteration 32000 42%) loss = 1.5940\n",
      "(iteration 33000 44%) loss = 1.5078\n",
      "(iteration 34000 45%) loss = 1.5746\n",
      "(iteration 35000 46%) loss = 1.4866\n",
      "(iteration 36000 48%) loss = 1.4782\n",
      "(iteration 37000 49%) loss = 1.4988\n",
      "(iteration 38000 50%) loss = 1.4262\n",
      "(iteration 39000 52%) loss = 1.4156\n",
      "(iteration 40000 53%) loss = 1.4180\n",
      "(iteration 41000 54%) loss = 1.3893\n",
      "(iteration 42000 56%) loss = 1.2902\n",
      "(iteration 43000 57%) loss = 1.2621\n",
      "(iteration 44000 58%) loss = 1.2983\n",
      "(iteration 45000 60%) loss = 1.3003\n",
      "(iteration 46000 61%) loss = 1.2625\n",
      "(iteration 47000 62%) loss = 1.2174\n",
      "(iteration 48000 64%) loss = 1.2138\n",
      "(iteration 49000 65%) loss = 1.1466\n",
      "(iteration 50000 66%) loss = 1.1704\n",
      "(iteration 51000 68%) loss = 1.1613\n",
      "(iteration 52000 69%) loss = 1.1508\n",
      "(iteration 53000 70%) loss = 1.1427\n",
      "(iteration 54000 72%) loss = 1.1383\n",
      "(iteration 55000 73%) loss = 1.0742\n",
      "(iteration 56000 74%) loss = 1.0700\n",
      "(iteration 57000 76%) loss = 1.0533\n",
      "(iteration 58000 77%) loss = 1.0086\n",
      "(iteration 59000 78%) loss = 1.0283\n",
      "(iteration 60000 80%) loss = 1.0118\n",
      "(iteration 61000 81%) loss = 0.9991\n",
      "(iteration 62000 82%) loss = 0.9865\n",
      "(iteration 63000 84%) loss = 0.9698\n",
      "(iteration 64000 85%) loss = 0.9151\n",
      "(iteration 65000 86%) loss = 0.9139\n",
      "(iteration 66000 88%) loss = 0.9571\n",
      "(iteration 67000 89%) loss = 0.8883\n",
      "(iteration 68000 90%) loss = 0.8944\n",
      "(iteration 69000 92%) loss = 0.8888\n",
      "(iteration 70000 93%) loss = 0.9021\n",
      "(iteration 71000 94%) loss = 0.8848\n",
      "(iteration 72000 96%) loss = 0.8174\n",
      "(iteration 73000 97%) loss = 0.8345\n",
      "(iteration 74000 98%) loss = 0.7849\n",
      "(iteration 75000 100%) loss = 0.7976\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoder = Encoder(input_lang.n_words, hidden_size).to(device)\n",
    "decoder = Decoder(hidden_size, output_lang.n_words).to(device)\n",
    "\n",
    "trainIters(encoder, decoder, 75000, print_every=1000,plot_every=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4. Inference\n",
    "\n",
    "For inference, the only difference with training is that we will continue to feed back the network's predictions to itself at each step, and stop only when we predict an end of sentence token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(encoder, decoder, sentence, max_length=max_length):\n",
    "    \n",
    "    with torch.no_grad(): #Freeze gradient\n",
    "        \n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        \n",
    "        #Initialize the encoder hidden states\n",
    "        encoder_hidden = torch.randn(1, 1, hidden_size)\n",
    "        encoder_cell = torch.randn(1, 1, hidden_size)\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        ##ENCODER\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, (encoder_hidden,encoder_cell) = encoder(input_tensor[ei],\n",
    "                                                     (encoder_hidden,encoder_cell))\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        #Initialize decoder input with a start of sentence token\n",
    "        decoder_input = torch.tensor([[Start_sentence_token]], device=device) \n",
    "\n",
    "        #Feed the encoder context vectors to the decoder\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_cell=encoder_cell\n",
    "\n",
    "        decoded_words = [] #Will hold the decoded sequence (translation)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, (decoder_hidden,decoder_cell) = decoder(decoder_input, (decoder_hidden,decoder_cell))\n",
    "            \n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == End_sentence_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break #Stop if we predict an end of sentence token\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach() #Use the previously predicted token as the input for the next step\n",
    "\n",
    "        return decoded_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a util function that will evaluate 10 random sentences from the train set and try to translate them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words = inference(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> you re a good chess player .\n",
      "= vous etes un bon joueur d echecs .\n",
      "< tu es un bon joueur d echecs . <EOS>\n",
      "\n",
      "> i m not a good liar .\n",
      "= je ne suis pas un bon menteur .\n",
      "< je ne suis pas une bonne menteuse . <EOS>\n",
      "\n",
      "> he s not sure he s ready .\n",
      "= il n est pas sur d etre pret .\n",
      "< il n est pas sur d etre pret . <EOS>\n",
      "\n",
      "> we re astonished .\n",
      "= nous sommes stupefaits .\n",
      "< nous sommes en train d etre de nous . <EOS>\n",
      "\n",
      "> they re all here .\n",
      "= ils sont tous ici .\n",
      "< ils sont toutes la . <EOS>\n",
      "\n",
      "> he is ashamed to ask questions .\n",
      "= il a honte de poser des questions .\n",
      "< j ai honte de dormir a l anglais . <EOS>\n",
      "\n",
      "> i m from the west coast .\n",
      "= je suis de la cote ouest .\n",
      "< je suis de la cote cote . <EOS>\n",
      "\n",
      "> you re really hard to understand .\n",
      "= tu es vraiment difficile a comprendre .\n",
      "< vous etes vraiment difficile a comprendre . <EOS>\n",
      "\n",
      "> i am anxious about his health .\n",
      "= je suis inquiet pour sa sante .\n",
      "< je suis inquiet pour sa voiture . <EOS>\n",
      "\n",
      "> i m sure we can work this out .\n",
      "= je suis sur que nous pouvons arranger ca .\n",
      "< je suis sur que nous pouvons arranger cela . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder, decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After only a few training steps, we observe that translations are often all identical. It would take more several thousands of training iterations (probably about 100 000) to reach a satisfying result with this system. There are two main reasons that can explain this problem :\n",
    "\n",
    "- First, the **use of teacher forcing**. Because we systematically correct the predictions of the network during training, the system has a tendency to learn to predict sentences that are grammatically correct, but would fail to learn the actual meaning. As an exercise, we could try to modfy the train function to not include teacher forcing. The flexibility of PyTorch also allows us to use teacher forcing sometimes, but not always.\n",
    "- Then, the **architecture of the network**. Here, because the context vectors fed into the decoder are the same for a given input sentence, this means that the encoder has the responsibility to learn representations for the input sequence ***in its entirety***. For longer sentences, this isquite unefficient. In the rest of this notebook, we will introduce the notion of attention, as a response to this issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Using Attention\n",
    "\n",
    "A variant of the previous Seq2Seq system involves a mechanism mimicking **attention**. With this mechanism, instead of conditionning the prediction using the raw context vector, we will apply attention weights In practice, this means that the system will learn to \"use\" some parts of the encoder output more than others when predicting a sequence.\n",
    "\n",
    "## 5.1. Implementing a decoder with attention\n",
    "\n",
    "In this paradigm, encoding is performed in the same way as previously. \n",
    "\n",
    "In the previous system, the decoder predicted the next token of the target sequence based on the known one. This prediction was conditioned by the encoded context vectors.\n",
    "The difference here is that instead of directly predicting the next token from the input, the decoder will first predict where to focus its attention on the encoded sequence, and will then use this attended vector as well as the input topredict what the next token is.\n",
    "\n",
    "Let's write the new version of our decoder :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoder(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=max_length):\n",
    "        super(AttnDecoder, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p #dropout probability\n",
    "        self.max_length = max_length\n",
    "\n",
    "        #Embedding layers for the decoder input\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        \n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        \n",
    "        self.lstm = nn.LSTM(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        \n",
    "        #First, the input (target sequence) is embedded. Some weights are randomly zeroed out to facilitate\n",
    "        #learning with the attention mechanism\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        \n",
    "        #Attention is computed by combining the context vectors and the embedded input (french sequence)\n",
    "        attn_weights = F.softmax(self.attn(torch.cat((embedded[0], hidden[0][0]), 1)), dim=1)\n",
    "        #Attention is applied on the encoded original sentence (in english)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        #We retrieve the embedded input and the context vector (with attention applied), and combine the two tensors\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "        output = F.relu(output)\n",
    "        \n",
    "        #The attended part of the input is fed into the lstm, conditioned by the hidden and cell states\n",
    "        output, hidden = self.lstm(output, hidden)\n",
    "        #Retrieve token probabilities\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        \n",
    "        #In addition to the output and hidden states that are necessary for iterating, we return the attention\n",
    "        #weights, that will provide some form of explainability\n",
    "        return output, hidden, attn_weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the input and output of the forward pass of this decoder is not the same as before (we added the attention weights and encoder output), we need to adapt the train, trainIter and inference functions :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_attention(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=max_length):\n",
    "\n",
    "    encoder_hidden = torch.randn(1, 1, hidden_size)\n",
    "    encoder_cell = torch.randn(1, 1, hidden_size)\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, (encoder_hidden,encoder_cell) = encoder(input_tensor[ei], (encoder_hidden,encoder_cell))\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[Start_sentence_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "    decoder_cell = encoder_cell\n",
    "    \n",
    "    # THE ONLY CHANGES OCCURS HERE, AS WE NEED TO ADD encoder_output AS AN INPUT AND attention AS AN OUTPUT\n",
    "    for di in range(target_length):\n",
    "        decoder_output, (decoder_hidden,decoder_cell), decoder_attention  = decoder(decoder_input, (decoder_hidden,decoder_cell), encoder_outputs)\n",
    "        loss += criterion(decoder_output, target_tensor[di])\n",
    "        decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length\n",
    "\n",
    "#Iterations of training\n",
    "def trainIters_with_attention(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0\n",
    "    plot_loss_total = 0 \n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs)) for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "        \n",
    "        #THE ONLY CHANGE HAPPENS HERE, AS WE NEED TO CALL THE TRAIN_WITH_ATTENTION FUNCTION\n",
    "        loss = train_with_attention(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('(iteration %d %d%%) loss = %.4f' % (iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)\n",
    "  \n",
    "#evaluation function\n",
    "def inference_with_attention(encoder, decoder, sentence, max_length=max_length):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = torch.randn(1, 1, hidden_size)\n",
    "        encoder_cell = torch.randn(1, 1, hidden_size)\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, (encoder_hidden,encoder_cell) = encoder(input_tensor[ei],\n",
    "                                                     (encoder_hidden,encoder_cell))\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[Start_sentence_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_cell = encoder_cell\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        # ONLY CHANGE IS HERE\n",
    "        for di in range(max_length):\n",
    "            decoder_output, (decoder_hidden,decoder_cell), decoder_attention = decoder(\n",
    "                decoder_input, (decoder_hidden,decoder_cell), encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == End_sentence_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]\n",
    "\n",
    "#evaluate several sentences picked randomly    \n",
    "def evaluateRandomly_with_attention(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = inference_with_attention(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train and test this system !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(iteration 100 10%) loss = 7.0271\n",
      "(iteration 200 20%) loss = 5.0872\n",
      "(iteration 300 30%) loss = 4.4355\n",
      "(iteration 400 40%) loss = 4.1733\n",
      "(iteration 500 50%) loss = 3.9742\n",
      "(iteration 600 60%) loss = 4.0786\n",
      "(iteration 700 70%) loss = 4.0249\n",
      "(iteration 800 80%) loss = 3.9406\n",
      "(iteration 900 90%) loss = 3.7225\n",
      "(iteration 1000 100%) loss = 3.6683\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoder_for_attn = Encoder(input_lang.n_words, hidden_size).to(device)\n",
    "attn_decoder = AttentionDecoder(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "\n",
    "trainIters_with_attention(encoder_for_attn, attn_decoder, 1000, print_every=100,plot_every=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> i m worried about you .\n",
      "= je m inquiete pour toi .\n",
      "< je suis inquiet a vous . <EOS>\n",
      "\n",
      "> you re right on time .\n",
      "= vous etes juste a l heure .\n",
      "< tu es a l heure . <EOS>\n",
      "\n",
      "> i m feeling kind of tired .\n",
      "= je me sens un peu fatigue .\n",
      "< je me sens plutot fatigue . <EOS>\n",
      "\n",
      "> you re the same age as my girlfriend .\n",
      "= tu as le meme age que ma copine .\n",
      "< tu as le meme age que ma copine . <EOS>\n",
      "\n",
      "> i m not making any plans .\n",
      "= je ne fais pas le moindre projet .\n",
      "< je ne fais pas de l argent . <EOS>\n",
      "\n",
      "> she s not admitting her mistake .\n",
      "= elle n admet pas son erreur .\n",
      "< elle n admet pas son erreur . <EOS>\n",
      "\n",
      "> you re sleepy so go to bed .\n",
      "= vous avez sommeil donc allez vous coucher .\n",
      "< vous etes tellement difficile a te aller . <EOS>\n",
      "\n",
      "> i m right here .\n",
      "= je suis juste ici .\n",
      "< je suis juste la . <EOS>\n",
      "\n",
      "> we re all alone .\n",
      "= nous sommes tous seuls .\n",
      "< nous sommes tous seules . <EOS>\n",
      "\n",
      "> you re very brave .\n",
      "= vous etes tres courageux .\n",
      "< vous etes tres courageux . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly_with_attention(encoder_for_attn, attn_decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. Visualize attention\n",
    "\n",
    "One of the advantages of using attention is that it provides explainability of the output. As we have the ability to see what part of the sequence was attended to when predicting a given output token, it provides an explanation of correspondences between target and input tokens.\n",
    "\n",
    "In this section, we will write a function to visualize attention weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showAttention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
    "                       ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def evaluateAndShowAttention(input_sentence):\n",
    "    output_words, attentions = inference_with_attention(\n",
    "        encoder_for_attn, attn_decoder, input_sentence)\n",
    "    print('input =', input_sentence)\n",
    "    print('output =', ' '.join(output_words))\n",
    "    showAttention(input_sentence, output_words, attentions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = i am not making any plans .\n",
      "output = je ne fais pas de l argent . <EOS>\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluateAndShowAttention(\"i am not making any plans .\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Util : load or save a previous model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(attn_decoder,'att_decoder')\n",
    "torch.save(attn_encoder,'att_encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_decoder = torch.load('attn_decoder')\n",
    "encoder_for_attn=torch.load('attn_encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
